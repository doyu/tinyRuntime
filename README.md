---
title: "Demystifying Tiny Runtime"
subtitle: "The Unstoppable Rise of Disposable ML frameworks"
author: |
 | Hiroshi Doyu
 | hiroshi.doyu@ninjalabo.ai
theme: "metropolis"
fonttheme: "default"
fontsize: 20pt
urlcolor: blue
linkstyle: bold
aspectratio: 169
date: \today
section-titles: false
toc: true
#titlegraphic: images/logo-black.png
#logo: images/logo-black.png
---

This is for [EMEA 2024 Call for Presentations and Posters](https://www.tinyml.org/news/emea-2024-call-for-presentations-and-posters).

# Why disposable ML frameworks?

# ML Compiler


# References
- [The Unstoppable Rise of Disposable ML Frameworks](https://petewarden.com/2023/10/15/the-unstoppable-rise-of-disposable-ml-frameworks/)
- [Why Nvidiaâ€™s AI Supremacy is Only Temporary](https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-is-only-temporary/)
- [llama2.c, Inference Llama 2 in one file of pure C](https://github.com/karpathy/llama2.c)
- [llama.cpp, Inference of LLaMA model in pure C/C++](https://github.com/ggerganov/llama.cpp)
- [whispher.cpp](Port of OpenAI's Whisper model in C/C++)
- [GGML](https://github.com/ggerganov/ggml)
- [Useful Transformers](https://github.com/usefulsensors/useful-transformers)
- [DNN in parallel & pipe](https://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=5007&context=smallsat)


# Lectures
- [makemore](https://youtu.be/PaCmpygFfXo?si=gDgSeC_dqaLadV2s)
- [Let's build GPT: from scratch, in code, spelled out](https://youtu.be/kCc8FmEb1nY?si=etfHLcd90w9Hnqbj)
- [micrograd](https://youtu.be/VMj-3S1tku0?si=S0wJvNUlsXXiBQGx)
- [EfficientML.ai, Deep Compression](https://youtu.be/36S3yCY193M?si=M275AV1L_nE6eQR7)
